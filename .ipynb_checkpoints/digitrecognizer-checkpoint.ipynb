{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple backpropagation neural network\n",
    "This is an attempt to solve Kaggle MNIST competition with multilayer neural network. I'm writing a NN myself so that I can get a gist of how they work and whats the features of constructing such networks.\n",
    "\n",
    "#### Class Neuron\n",
    "This is just one neuron, it has weights of inputs and an output, it can calculate output for given vector of input values (i.e. spike) and it can learn (adjust weights according to given error rate sigma). There is also a setter for a learning rate alpha which can be helpful in some situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import derivative\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, in_size, alpha):\n",
    "        self.weights = np.random.uniform(low = -0.1, high = 0.1, size = in_size + 1)\n",
    "        self.alpha = alpha\n",
    "        self.out = 0\n",
    "        \n",
    "    def setLearnRate(self, newalpha):\n",
    "        self.alpha = newalpha\n",
    "        \n",
    "    def actvF(self, s):\n",
    "        return 1/(1 + np.exp(-s))\n",
    "        \n",
    "    def spike(self, sample):\n",
    "        s = sum(self.weights * np.append(sample, 1))\n",
    "        self.out = self.actvF(s)\n",
    "        return self.out\n",
    "        \n",
    "    def learn(self, sample, sigma, nxt_wt = None):\n",
    "        sample = np.append(sample, 1)\n",
    "        if nxt_wt is None:\n",
    "            # this is a neuron of the last layer, passing sigma unchanged\n",
    "            for i, e in enumerate(self.weights):\n",
    "                self.weights[i] -= self.alpha * sigma * sample[i]\n",
    "        else:\n",
    "            # this one isn't in the last layer, so need to recalculate error (sigma) and pass it further\n",
    "            for i, e in enumerate(self.weights):\n",
    "                self.weights[i] -= self.alpha * sum(sigma * nxt_wt) * self.out * (1 - self.out) * sample[i]\n",
    "            sigma = sum(sigma * nxt_wt) * derivative(self.actvF, sum(self.weights * sample))\n",
    "        return sigma\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class NLayer\n",
    "NLayer is a one layer of neurons and is sort of a wrapper for neurons array. To create a neuron layer you need to specify the size of its input vector, a number of neurons, their initial learning rate and the following layer. Unlike Neuron class, NLayer stores an input value which can be set with setInput function. This class also has a setLearnRate function that calls the corresponding function for each neuron.\n",
    "\n",
    "For calculating an output there are two functions, process and process_mt, they are doing basically the same thing (which is just calling spike fucntion for each neuron) but process_mt is trying to do so in a parallel and sort of a map-reduce manner. It works much slower though and I do recommend to ignore this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class NLayer:\n",
    "    def __init__(self, in_size, n_neurons, alpha, nxt = None):\n",
    "        self.in_size = in_size\n",
    "        self.n_neurons = n_neurons\n",
    "        self.neurons = np.empty(n_neurons, dtype = object)\n",
    "        for i in range(self.n_neurons):\n",
    "            self.neurons[i] = Neuron(in_size, alpha)\n",
    "        self.nxt = nxt\n",
    "        \n",
    "    def setLearnRate(self, newalpha):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.setLearnRate(newalpha)\n",
    "            \n",
    "    def setInput(self, sample):\n",
    "        self.in_signal = sample\n",
    "        \n",
    "    def process(self, neurons = None): \n",
    "        if neurons == None:\n",
    "            neurons = self.neurons\n",
    "            self.output = np.empty(self.n_neurons)\n",
    "            for i in range(len(neurons)):\n",
    "                self.output[i] = neurons[i].spike(self.in_signal)\n",
    "            \n",
    "    def process_mt(self, nproc):\n",
    "        self.output = []\n",
    "        neuron_chunks = np.array_split(self.neurons, nproc)\n",
    "        treads = []\n",
    "        for i in range(nproc):\n",
    "            treads.append(threading.Thread(target = self.process, args = (neuron_chunks[i],)))\n",
    "        for t in treads:\n",
    "            t.start()\n",
    "            t.join()\n",
    "        self.output = np.array(self.output)\n",
    "            \n",
    "    def learn(self, sigmas):\n",
    "        if not self.nxt:\n",
    "            # this is the last layer\n",
    "            for k in range(self.n_neurons):\n",
    "                self.neurons[k].learn(self.in_signal, sigmas[k])\n",
    "            return sigmas\n",
    "        else:\n",
    "            self.sigmas = np.zeros(self.n_neurons)\n",
    "            for k in range(self.n_neurons):\n",
    "                nxt_wt = np.zeros(self.nxt.n_neurons)\n",
    "                for i in range(self.nxt.n_neurons):\n",
    "                    nxt_wt[i] = self.nxt.neurons[i].weights[k]\n",
    "                self.sigmas[k] = self.neurons[k].learn(self.in_signal, sigmas, nxt_wt)\n",
    "            return self.sigmas\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class NNetwork\n",
    "This is another wrapper but for layers now. To create a network one need to specify size of an input vector, size of a desired output, a list containing numbers of neurons for hidden layers and an initial learning rate. When created, it creates and arranges layers of specified sizes. Process function has an argument npoc which is for parallel processing and is not suggested as I said it a description of a layer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NNetwork:    \n",
    "    def __init__(self, in_size, out_size, hiddlist, alpha = 0.01):\n",
    "        self.layers = np.empty(len(hiddlist) + 1, dtype = object)\n",
    "        self.layers[-1] = NLayer(hiddlist[-1], out_size, alpha)\n",
    "        for i in range(1, len(hiddlist))[::-1]:\n",
    "            self.layers[i] = NLayer(hiddlist[i-1], hiddlist[i], alpha, nxt = self.layers[i+1])\n",
    "        self.layers[0] = NLayer(in_size, hiddlist[0], alpha, nxt = self.layers[1])\n",
    "        \n",
    "    def setLearnRate(self, newalpha):\n",
    "        for layer in self.layers:\n",
    "            layer.setLearnRate(newalpha)\n",
    "        \n",
    "    def printLayers(self):\n",
    "        for i, l in enumerate(self.layers):\n",
    "            print(l.in_size, l.n_neurons, l.nxt)\n",
    "            \n",
    "    def process(self, sample, nproc = None):\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                self.layers[i].setInput(sample)\n",
    "            else:\n",
    "                self.layers[i].setInput(self.layers[i-1].output)\n",
    "            if nproc == None:\n",
    "                self.layers[i].process()\n",
    "            else:\n",
    "                self.layers[i].process_mt(nproc)\n",
    "            \n",
    "        self.answer = self.layers[-1].output\n",
    "        return self.answer\n",
    "        \n",
    "    def learn(self, d):\n",
    "        sigmas = np.empty(len(d))\n",
    "        for i in range(len(d)):\n",
    "            sigmas[i] = (self.layers[-1].neurons[i].out - d[i]) * self.layers[-1].neurons[i].out * (1 - self.layers[-1].neurons[i].out)\n",
    "            \n",
    "        for i in range(len(self.layers))[::-1]:\n",
    "            sigmas = self.layers[i].learn(sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is small functions made for the purposes of digit recognition. labelToArray transforms digit in a binary format and arrayToLabel is doing the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelToArray(data):\n",
    "    binstring = \"{0:b}\".format(data)\n",
    "    missing = (4 - len(binstring)) * '0'\n",
    "    return [int(s) for s in missing + binstring]\n",
    "\n",
    "def arrayToLabel(arr):\n",
    "    arr = [int(round(x)) for x in arr]\n",
    "    s = ''.join(map(str, arr))\n",
    "    return int(s, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So let's give it a try!\n",
    "In here we're just reading a part of MNIST handwritten digits down and splitting'em into test and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "rawtrain = read_csv('train.csv', nrows=10000).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawtrain[:, 1:], rawtrain[:, 0], test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reducing dimensionality with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a neural network with an input size equals to the number of variables in our training data, output of size 4 (since we only have digits from 0 to 9 and need 4 bits to represent them binarily) and one hidden layer of size 100. Not too complex :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "net = NNetwork(X_train_pca.shape[1], 4, [100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's time to learn this network. We are going to make it in 5 epochs with decresing learning rate. And we'll measure the time of execution as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "0%                                                                  100%\n",
      "[######################################################################] | ETA[sec]: 0.000 \n",
      "Total time elapsed: 756.247 sec\n",
      "Epoch 2\n",
      "0%                                                                  100%\n",
      "[######################################################################] | ETA[sec]: 0.000 \n",
      "Total time elapsed: 753.861 sec\n",
      "Epoch 3\n",
      "0%                                                                  100%\n",
      "[######################################################################] | ETA[sec]: 0.000 \n",
      "Total time elapsed: 736.626 sec\n",
      "Epoch 4\n",
      "0%                                                                  100%\n",
      "[######################################################################] | ETA[sec]: 0.000 \n",
      "Total time elapsed: 720.122 sec\n",
      "Epoch 5\n",
      "0%                                                                  100%\n",
      "[######################################################################] | ETA[sec]: 0.000 \n",
      "Total time elapsed: 719.147 sec\n",
      "Overall time: 1:01:26.020501\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "from datetime import datetime\n",
    "\n",
    "learnrate = 0.02\n",
    "net.setLearnRate(learnrate)\n",
    "\n",
    "nEpochs = 5\n",
    "start = datetime.now()\n",
    "\n",
    "for epoch in range(nEpochs):\n",
    "    print('Epoch ' + str(epoch + 1))\n",
    "    for i in pyprind.prog_bar(range(len(y_train)), stream = 1, width = 70):\n",
    "        answer = labelToArray(y_train[i])\n",
    "        net.process(X_train_pca[i])\n",
    "        net.learn(answer)\n",
    "    learnrate /= 2\n",
    "    net.setLearnRate(learnrate)\n",
    "        \n",
    "overalltime = datetime.now() - start\n",
    "print('Overall time:', overalltime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.97 %\n"
     ]
    }
   ],
   "source": [
    "answers = np.empty(len(y_test))\n",
    "X_test_pca = pca.transform(X_test)\n",
    "for i in range(len(y_test)):\n",
    "    ans = net.process(X_test_pca[i])\n",
    "    if y_test[i] == arrayToLabel(ans):\n",
    "        answers[i] = True\n",
    "    else:\n",
    "        answers[i] = False\n",
    "        \n",
    "print(round(sum(answers) / len(y_test) * 100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope it turned out to be more than 10% which is just an accuracy of random guessing.\n",
    "\n",
    "To check networks performance in a bit more detailed fashion we can look at a random observation form a test set and examine an overall apperance of the digit and a raw output of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7a4d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: 4\n",
      "NN raw output: [ 0.26133157  0.81609907  0.37799165  0.41461725]\n",
      "NN labeled output: 4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = np.random.randint(0, len(y_test))\n",
    "\n",
    "sample = X_test[n]\n",
    "sample = np.reshape(sample, (28, 28))\n",
    "\n",
    "%matplotlib inline\n",
    "plot = plt.imshow(sample)\n",
    "plot.set_cmap('gray_r')\n",
    "plt.show()\n",
    "\n",
    "print('Actual label:', y_test[n])\n",
    "a = net.process(X_test_pca[n])\n",
    "print('NN raw output:', a)\n",
    "print('NN labeled output:', arrayToLabel(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
